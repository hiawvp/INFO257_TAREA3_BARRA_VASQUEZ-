{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import vocab\n",
    "from torchtext import data\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = partial(casual_tokenize, preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=tokenizer,\n",
    "                  batch_first=True)\n",
    "\n",
    "LABEL = data.LabelField(dtype=torch.long,\n",
    "                        batch_first=True,\n",
    "                       #sequential=False\n",
    "                       )\n",
    "\n",
    "fields = [('text', TEXT), ('i_label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = data.TabularDataset.splits(path = '',\n",
    "                                                    train='train.csv',\n",
    "                                                    validation='valid.csv',\n",
    "                                                    format = 'csv',\n",
    "                                                    fields = fields,\n",
    "                                                    skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usar min freq? max_size?\n",
    "\n",
    "#https://github.com/dccuchile/spanish-word-embeddings\n",
    "vec = vocab.Vectors('glove-sbwc.i25.vec')\n",
    "TEXT.build_vocab(train_data,\n",
    "                 vectors=vec,\n",
    "                 unk_init=torch.Tensor.normal_,\n",
    "                 max_size=15000)  \n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15002\n",
      "[('de', 56807), (',', 54810), ('.', 36094), ('la', 33320), ('el', 29547), ('que', 28338), ('en', 27223), ('y', 19726), ('a', 19136), ('los', 14248)]\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab))\n",
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = data.BucketIterator(train_data, \n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    device=device)\n",
    "\n",
    "valid_iterator = data.BucketIterator(valid_data, \n",
    "                                    batch_size=BATCH_SIZE*2,\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_filters, output_dim, emb_vec,\n",
    "                 filter_sizes=[3, 4, 5, 6, 7], freeze=True, dropout=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        vocab_size = emb_vec.size()[0]\n",
    "        emb_dim = emb_vec.size()[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(emb_vec, freeze=freeze)        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, emb_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters,\n",
    "                            output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        embedded = self.embedding(text)       \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        out = (self.fc(cat)).squeeze(1)\n",
    "        return self.act(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 100\n",
    "OUTPUT_DIM = 7\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model = CNN(N_FILTERS, OUTPUT_DIM, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.NLLLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(15002, 300)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (3): Conv2d(1, 100, kernel_size=(6, 300), stride=(1, 1))\n",
      "    (4): Conv2d(1, 100, kernel_size=(7, 300), stride=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=500, out_features=7, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (act): LogSoftmax(dim=1)\n",
      ")\n",
      "The model has 754,007 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca:1 \t Loss: 0.84 \t  Accuracy: 0.71\ttiempo 30.73\n",
      "Epoca:2 \t Loss: 0.73 \t  Accuracy: 0.75\ttiempo 30.05\n",
      "Epoca:3 \t Loss: 0.69 \t  Accuracy: 0.76\ttiempo 30.12\n",
      "Epoca:4 \t Loss: 0.66 \t  Accuracy: 0.77\ttiempo 29.94\n",
      "Epoca:5 \t Loss: 0.65 \t  Accuracy: 0.78\ttiempo 30.01\n",
      "Epoca:6 \t Loss: 0.65 \t  Accuracy: 0.78\ttiempo 29.98\n",
      "Epoca:7 \t Loss: 0.67 \t  Accuracy: 0.78\ttiempo 29.91\n",
      "Epoca:8 \t Loss: 0.67 \t  Accuracy: 0.79\ttiempo 29.92\n",
      "Epoca:9 \t Loss: 0.72 \t  Accuracy: 0.77\ttiempo 29.94\n",
      "Epoca:10 \t Loss: 0.69 \t  Accuracy: 0.79\ttiempo 29.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 1460\n",
       "\tepoch: 10\n",
       "\tepoch_length: 146\n",
       "\tmax_epochs: 10\n",
       "\toutput: 0.03309398517012596\n",
       "\tbatch: <class 'torchtext.data.batch.Batch'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torchtext.data.iterator.BucketIterator'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.handlers import Timer\n",
    "\n",
    "max_epochs = 10\n",
    "t = Timer(average=True)\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion) # Creo un engine para entrenar\n",
    "metrics = {'Loss': Loss(criterion), 'Acc': Accuracy()}\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics) # Creo un engine para validar\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "def log_results(engine):\n",
    "    evaluator.run(valid_iterator) # Evaluo el conjunto de validación\n",
    "    loss = evaluator.state.metrics['Loss']\n",
    "    acc = evaluator.state.metrics['Acc']\n",
    "    t.step()\n",
    "    print(f\"Epoca:{engine.state.epoch}\"\n",
    "          +f\" \\t Loss: {loss:.2f} \\t  Accuracy: {acc:.2f}\\ttiempo {t.value():.2f}\")\n",
    "best_model_handler = ModelCheckpoint(dirname='.', require_empty=False,\n",
    "                                     filename_prefix=\"best\", n_saved=1,\n",
    "                                     score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                     score_name=\"val_loss\")\n",
    "\n",
    "# Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "evaluator.add_event_handler(Events.COMPLETED,\n",
    "                            best_model_handler, {'mymodel': model})\n",
    "\n",
    "trainer.run(train_iterator, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.TabularDataset('test.csv',\n",
    "                                format = 'csv',\n",
    "                                fields = fields,\n",
    "                                skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = data.BucketIterator(test_data, \n",
    "                                    batch_size = BATCH_SIZE*2,\n",
    "                                    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7882117882117882\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_mymodel_val_loss=-0.6461.pt'))\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics)\n",
    "evaluator.run(test_iterator)\n",
    "print(evaluator.state.metrics['Acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = [ 'cultura',\n",
    "         'deportes',\n",
    "         'economia',\n",
    "         'mundo',\n",
    "         'pais',\n",
    "         'tecnologias',\n",
    "         'tendencias' ]\n",
    "\n",
    "\n",
    "def predict(model, sentence):\n",
    "    tokenized = [tok for tok in tokenizer(sentence)]\n",
    "    tokenized = tokenized + [\" \" for i in range(10 - len(tokenized))]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          \n",
    "    tensor = torch.LongTensor(indexed).to(device)              \n",
    "    tensor = tensor.unsqueeze(1).T                          \n",
    "    prediction = model(tensor)\n",
    "    return int(torch.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deportes'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd2 = \"\"\"\n",
    "Los pilotos chilenos Francisco “Chaleco” López e Ignacio “Perro” Casale aseguraron este\n",
    "martes, mediante una video conferencia, estar listos y en cuarentena preventiva para\n",
    "viajar a competir en el Rally Dakar 2021, que en su cuadragésima tercera edición \n",
    "y por segundo año consecutivo, se vivirá en las exigentes tierras y desiertos de \n",
    "Arabia Saudita.\n",
    "Ambos pilotos admitieron que les acomoda y agrada la sede de la exigente competición, \n",
    "recordando el haber competido en enero del presente año en dichas tierras y caminos. \n",
    "De hecho, Casale terminó en el primer lugar en la Categoría Quads y López concluyó \n",
    "tercero en la de Side by Side, lo cual les brinda cierta ventaja y conocimiento de los \n",
    "duros caminos y dunas a los que se deberán enfrentar.\n",
    "\"\"\"\n",
    "lbls[predict(model, xd2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('test.csv')\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = [predict(model, noticia) for noticia in test_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     cultura       0.82      0.92      0.87       143\n",
      "    deportes       0.91      0.88      0.90       143\n",
      "    economia       0.71      0.77      0.74       143\n",
      "       mundo       0.82      0.77      0.79       143\n",
      "        pais       0.74      0.76      0.75       143\n",
      " tecnologias       0.80      0.69      0.74       143\n",
      "  tendencias       0.68      0.69      0.68       143\n",
      "\n",
      "    accuracy                           0.78      1001\n",
      "   macro avg       0.78      0.78      0.78      1001\n",
      "weighted avg       0.78      0.78      0.78      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['i_label'], predictions, target_names=lbls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
